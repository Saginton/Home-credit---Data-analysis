{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # implement here all desired dtypes for tables\n",
    "    # the following is just an example\n",
    "    for col in df.columns:\n",
    "        # last letter of column name will help you determine the type\n",
    "        if col[-1] in (\"P\", \"A\"):\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:  \n",
    "        if df[col].dtype.name in ['object', 'string']:\n",
    "            df[col] = df[col].astype(\"string\").astype('category')\n",
    "            current_categories = df[col].cat.categories\n",
    "            new_categories = current_categories.to_list() + [\"Unknown\"]\n",
    "            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n",
    "            df[col] = df[col].astype(new_dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basetable = pl.read_csv(\"csv_files/train/train_base.csv\")\n",
    "train_static = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(\"csv_files/train/train_static_0_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"csv_files/train/train_static_0_1.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"csv_files/test/test_static_0_2.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "train_static_cb = pl.read_csv(\"csv_files/train/train_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "train_person_1 = pl.read_csv(\"csv_files/train/train_person_1.csv\").pipe(set_table_dtypes) \n",
    "train_credit_bureau_b_2 = pl.read_csv(\"csv_files/train/train_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Polars DataFrames to Pandas for easier manipulation in later stages (optional)\n",
    "train_basetable = train_basetable.to_pandas()\n",
    "train_static = train_static.to_pandas()\n",
    "train_static_cb = train_static_cb.to_pandas()\n",
    "train_person_1 = train_person_1.to_pandas()\n",
    "\n",
    "# Example of a simple feature engineering function\n",
    "def create_features(base_table, static, static_cb, person_1):\n",
    "    # Join your tables here. Example:\n",
    "    df = pd.merge(base_table, static, on=\"case_id\", how=\"left\")\n",
    "    df = pd.merge(df, static_cb, on=\"case_id\", how=\"left\")\n",
    "    df = pd.merge(df, person_1, on=\"case_id\", how=\"left\")\n",
    "    \n",
    "    # Assuming `df` is your DataFrame after conversion to Pandas\n",
    "    df['annuity_income_ratio'] = df['annuity_780A'] / df['maininc_215A']\n",
    "    df['avg_outstanding_balance_income_ratio'] = df['avgoutstandbalancel6m_4187114A'] / df['maininc_215A']\n",
    "    df['payment_income_ratio_12m'] = df['avgpmtlast12m_4525200A'] / df['maininc_215A']\n",
    "    df['debt_credit_ratio'] = df['totaldebt_9A'] / df['credamount_770A']\n",
    "    \n",
    "    df['bankacctype_710L'] = df['bankacctype_710L'].astype('category')\n",
    "    # Assuming 'df' is your DataFrame\n",
    "    # Select only numeric columns for median calculation\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Calculate the median only for numeric columns\n",
    "    numeric_medians = numeric_df.median()\n",
    "\n",
    "    # Fill missing values in numeric columns with their respective medians\n",
    "    df.fillna(numeric_medians, inplace=True)\n",
    "        \n",
    "    # Convert categorical variables to type 'category' for LightGBM, XGBoost, and CatBoost\n",
    "    df = convert_strings(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = create_features(train_basetable, train_static, train_static_cb, train_person_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1653.63 MB\n",
      "Memory usage after optimization is: 1613.92 MB\n",
      "Decreased by 2.4%\n",
      "date_decision       0\n",
      "bankacctype_710L    0\n",
      "cardtype_51L        0\n",
      "dtype: int64\n",
      "date_decision       object\n",
      "bankacctype_710L    object\n",
      "cardtype_51L        object\n",
      "dtype: object\n",
      "date_decision       0\n",
      "bankacctype_710L    0\n",
      "cardtype_51L        0\n",
      "dtype: int64\n",
      "date_decision       object\n",
      "bankacctype_710L    object\n",
      "cardtype_51L        object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "features data: pandas.DataFrame column 'clientscnt_136L' has dtype 'category' but is not in  cat_features list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 111\u001b[0m\n\u001b[0;32m    102\u001b[0m cbt_model \u001b[38;5;241m=\u001b[39m cbt\u001b[38;5;241m.\u001b[39mCatBoostClassifier(\n\u001b[0;32m    103\u001b[0m     iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m    104\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     cat_features \u001b[38;5;241m=\u001b[39m cat_features\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Fit the CatBoost model\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m cbt_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    112\u001b[0m     X_train, y_train, \n\u001b[0;32m    113\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_val, y_val)],\n\u001b[0;32m    114\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    115\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\catboost\\core.py:5201\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5199\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, cat_features, text_features, embedding_features, \u001b[38;5;28;01mNone\u001b[39;00m, sample_weight, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, baseline, use_best_model,\n\u001b[0;32m   5202\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5203\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\catboost\\core.py:2381\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES \u001b[38;5;241m+\u001b[39m (Pool,)):\n\u001b[0;32m   2379\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2381\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_train_params(\n\u001b[0;32m   2382\u001b[0m     X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, cat_features\u001b[38;5;241m=\u001b[39mcat_features, text_features\u001b[38;5;241m=\u001b[39mtext_features, embedding_features\u001b[38;5;241m=\u001b[39membedding_features,\n\u001b[0;32m   2383\u001b[0m     pairs\u001b[38;5;241m=\u001b[39mpairs, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, group_id\u001b[38;5;241m=\u001b[39mgroup_id, group_weight\u001b[38;5;241m=\u001b[39mgroup_weight,\n\u001b[0;32m   2384\u001b[0m     subgroup_id\u001b[38;5;241m=\u001b[39msubgroup_id, pairs_weight\u001b[38;5;241m=\u001b[39mpairs_weight, baseline\u001b[38;5;241m=\u001b[39mbaseline, use_best_model\u001b[38;5;241m=\u001b[39muse_best_model,\n\u001b[0;32m   2385\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39meval_set, verbose\u001b[38;5;241m=\u001b[39mverbose, logging_level\u001b[38;5;241m=\u001b[39mlogging_level, plot\u001b[38;5;241m=\u001b[39mplot, plot_file\u001b[38;5;241m=\u001b[39mplot_file,\n\u001b[0;32m   2386\u001b[0m     column_description\u001b[38;5;241m=\u001b[39mcolumn_description, verbose_eval\u001b[38;5;241m=\u001b[39mverbose_eval, metric_period\u001b[38;5;241m=\u001b[39mmetric_period,\n\u001b[0;32m   2387\u001b[0m     silent\u001b[38;5;241m=\u001b[39msilent, early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds, save_snapshot\u001b[38;5;241m=\u001b[39msave_snapshot,\n\u001b[0;32m   2388\u001b[0m     snapshot_file\u001b[38;5;241m=\u001b[39msnapshot_file, snapshot_interval\u001b[38;5;241m=\u001b[39msnapshot_interval, init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m   2389\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[0;32m   2390\u001b[0m )\n\u001b[0;32m   2391\u001b[0m params \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2392\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\catboost\\core.py:2261\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[0;32m   2258\u001b[0m text_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2259\u001b[0m embedding_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2261\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[0;32m   2262\u001b[0m                                sample_weight, group_id, group_weight, subgroup_id, pairs_weight,\n\u001b[0;32m   2263\u001b[0m                                baseline, column_description)\n\u001b[0;32m   2264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_pool\u001b[38;5;241m.\u001b[39mis_empty_:\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\catboost\\core.py:1499\u001b[0m, in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1498\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1499\u001b[0m     train_pool \u001b[38;5;241m=\u001b[39m Pool(X, y, cat_features\u001b[38;5;241m=\u001b[39mcat_features, text_features\u001b[38;5;241m=\u001b[39mtext_features, embedding_features\u001b[38;5;241m=\u001b[39membedding_features, pairs\u001b[38;5;241m=\u001b[39mpairs, weight\u001b[38;5;241m=\u001b[39msample_weight, group_id\u001b[38;5;241m=\u001b[39mgroup_id,\n\u001b[0;32m   1500\u001b[0m                       group_weight\u001b[38;5;241m=\u001b[39mgroup_weight, subgroup_id\u001b[38;5;241m=\u001b[39msubgroup_id, pairs_weight\u001b[38;5;241m=\u001b[39mpairs_weight, baseline\u001b[38;5;241m=\u001b[39mbaseline)\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_pool\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\catboost\\core.py:844\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[0;32m    839\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[0;32m    840\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m             )\n\u001b[1;32m--> 844\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0;32m    845\u001b[0m                    group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\catboost\\core.py:1477\u001b[0m, in \u001b[0;36mPool._init\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1476\u001b[0m     feature_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[1;32m-> 1477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0;32m   1478\u001b[0m                 group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n",
      "File \u001b[1;32m_catboost.pyx:4159\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4209\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4025\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:2919\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: features data: pandas.DataFrame column 'clientscnt_136L' has dtype 'category' but is not in  cat_features list"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type not in ['object', 'category']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            # Skip min/max operations for categorical or object columns\n",
    "            continue  # You can also convert to ordered categorical here if applicable\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "    print(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "for col in train_df.select_dtypes(include=['float16', 'float32', 'float64']).columns:\n",
    "    train_df[col] = train_df[col].fillna(train_df[col].median())\n",
    "\n",
    "# Now proceed with your train-test split and model training as before\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df.drop(['target', 'case_id'], axis=1),\n",
    "    train_df['target'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=5,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    force_col_wise=True\n",
    ")\n",
    "\n",
    "# Fit the LightGBM model with early stopping\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=True)]  # This is now correctly placed within fit_params\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=5, \n",
    "    learning_rate=0.05, \n",
    "    random_state=42, \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=50,  # Place early_stopping_rounds here\n",
    "    enable_categorical=True  # Ensure your XGBoost version supports this\n",
    ")\n",
    "\n",
    "# Fit the XGBoost model with early stopping\n",
    "xgb_model.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\"\"\"\n",
    "cat_features = ['date_decision', 'bankacctype_710L','cardtype_51L', 'clientscnt_136L']\n",
    "print(train_df[cat_features].isna().sum())  # Check for remaining NaN values\n",
    "print(train_df[cat_features].dtypes) \n",
    "\n",
    "for col in cat_features:\n",
    "    # For the training set\n",
    "    X_train[col] = X_train[col].astype(str).fillna('missing')\n",
    "    X_val[col] = X_val[col].astype(str).fillna('missing')\n",
    "\n",
    "print(train_df[cat_features].isna().sum())  # Check for remaining NaN values\n",
    "print(train_df[cat_features].dtypes) \n",
    "\n",
    "    \n",
    "\n",
    "cbt_model = cbt.CatBoostClassifier(\n",
    "    iterations=5, \n",
    "    learning_rate=0.05, \n",
    "    random_state=42, \n",
    "    verbose=100,\n",
    "    early_stopping_rounds=50,\n",
    "    cat_features = cat_features\n",
    ")\n",
    "# Fit the CatBoost model\n",
    "cbt_model.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
